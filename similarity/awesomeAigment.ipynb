{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbef0568-def7-488c-bc1b-fb3df62d85f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T13:24:03.403277Z",
     "iopub.status.busy": "2023-01-28T13:24:03.402819Z",
     "iopub.status.idle": "2023-01-28T13:24:07.742549Z",
     "shell.execute_reply": "2023-01-28T13:24:07.741431Z",
     "shell.execute_reply.started": "2023-01-28T13:24:03.403245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'awesome-align'...\n",
      "remote: Enumerating objects: 343, done.\u001b[K\n",
      "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 343 (delta 100), reused 88 (delta 88), pack-reused 230\u001b[K\n",
      "Receiving objects: 100% (343/343), 596.13 KiB | 964.00 KiB/s, done.\n",
      "Resolving deltas: 100% (207/207), done.\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/neulab/awesome-align\n",
    "!git clone https://github.com/neulab/awesome-align.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4bcb68-f158-485a-a4b3-edf2e3fdd630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T16:15:57.537215Z",
     "iopub.status.busy": "2023-03-09T16:15:57.536866Z",
     "iopub.status.idle": "2023-03-09T16:15:57.546657Z",
     "shell.execute_reply": "2023-03-09T16:15:57.545929Z",
     "shell.execute_reply.started": "2023-03-09T16:15:57.537185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/awesome-align\n"
     ]
    }
   ],
   "source": [
    "%cd awesome-align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90ed86a-d18e-4101-89fd-7e0e776e3030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T16:16:00.200268Z",
     "iopub.status.busy": "2023-03-09T16:16:00.199881Z",
     "iopub.status.idle": "2023-03-09T16:16:59.913045Z",
     "shell.execute_reply": "2023-03-09T16:16:59.912236Z",
     "shell.execute_reply.started": "2023-03-09T16:16:00.200240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/user/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tokenizers>=0.5.2\n",
      "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.2.0\n",
      "  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m166.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/user/miniconda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (4.61.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m166.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.26.87-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m178.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: requests in /home/user/miniconda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (2.25.1)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/user/miniconda/lib/python3.7/site-packages (from torch>=1.2.0->-r requirements.txt (line 2)) (4.4.0)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m209.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m182.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m165.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/user/miniconda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.2.0->-r requirements.txt (line 2)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wheel in /home/user/miniconda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.2.0->-r requirements.txt (line 2)) (0.36.2)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m151.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting botocore<1.30.0,>=1.29.87\n",
      "  Downloading botocore-1.29.87-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m158.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /home/user/miniconda/lib/python3.7/site-packages (from requests->-r requirements.txt (line 7)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/miniconda/lib/python3.7/site-packages (from requests->-r requirements.txt (line 7)) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/user/miniconda/lib/python3.7/site-packages (from requests->-r requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/miniconda/lib/python3.7/site-packages (from requests->-r requirements.txt (line 7)) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/user/miniconda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.87->boto3->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/miniconda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.87->boto3->-r requirements.txt (line 5)) (1.16.0)\n",
      "Installing collected packages: tokenizers, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, jmespath, filelock, nvidia-cudnn-cu11, botocore, torch, s3transfer, boto3\n",
      "Successfully installed boto3-1.26.87 botocore-1.29.87 filelock-3.9.0 jmespath-1.0.1 numpy-1.21.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 s3transfer-0.6.0 tokenizers-0.13.2 torch-1.13.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86fe61d5-2c91-42ab-98f4-879d19b4293f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T16:17:47.449976Z",
     "iopub.status.busy": "2023-03-09T16:17:47.449601Z",
     "iopub.status.idle": "2023-03-09T16:17:49.373942Z",
     "shell.execute_reply": "2023-03-09T16:17:49.372936Z",
     "shell.execute_reply.started": "2023-03-09T16:17:47.449944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing awesome_align.egg-info/PKG-INFO\n",
      "writing dependency_links to awesome_align.egg-info/dependency_links.txt\n",
      "writing entry points to awesome_align.egg-info/entry_points.txt\n",
      "writing requirements to awesome_align.egg-info/requires.txt\n",
      "writing top-level names to awesome_align.egg-info/top_level.txt\n",
      "reading manifest file 'awesome_align.egg-info/SOURCES.txt'\n",
      "writing manifest file 'awesome_align.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/modeling.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/run_align.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/tokenization_bert.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/__init__.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/train_utils.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/configuration_bert.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/modeling_utils.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/sparsemax.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/configuration_utils.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/activations.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/file_utils.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/tokenization_utils.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "copying build/lib/awesome_align/run_train.py -> build/bdist.linux-x86_64/egg/awesome_align\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/modeling.py to modeling.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/run_align.py to run_align.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/tokenization_bert.py to tokenization_bert.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/train_utils.py to train_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/configuration_bert.py to configuration_bert.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/modeling_utils.py to modeling_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/sparsemax.py to sparsemax.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/configuration_utils.py to configuration_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/activations.py to activations.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/file_utils.py to file_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/tokenization_utils.py to tokenization_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/awesome_align/run_train.py to run_train.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying awesome_align.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying awesome_align.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying awesome_align.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying awesome_align.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying awesome_align.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying awesome_align.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/awesome_align-0.1.7-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing awesome_align-0.1.7-py3.7.egg\n",
      "Copying awesome_align-0.1.7-py3.7.egg to /home/user/miniconda/lib/python3.7/site-packages\n",
      "Adding awesome-align 0.1.7 to easy-install.pth file\n",
      "Installing awesome-align script to /home/user/miniconda/bin\n",
      "Installing awesome-train script to /home/user/miniconda/bin\n",
      "\n",
      "Installed /home/user/miniconda/lib/python3.7/site-packages/awesome_align-0.1.7-py3.7.egg\n",
      "Processing dependencies for awesome-align==0.1.7\n",
      "Searching for certifi>=2017.4.17\n",
      "Reading https://pypi.org/simple/certifi/\n",
      "Downloading https://files.pythonhosted.org/packages/71/4c/3db2b8021bd6f2f0ceb0e088d6b2d49147671f25832fb17970e9b583d742/certifi-2022.12.7-py3-none-any.whl#sha256=4ad3232f5e926d6718ec31cfc1fcadfde020920e278684144551c91769c7bc18\n",
      "Best match: certifi 2022.12.7\n",
      "Processing certifi-2022.12.7-py3-none-any.whl\n",
      "Installing certifi-2022.12.7-py3-none-any.whl to /home/user/miniconda/lib/python3.7/site-packages\n",
      "Adding certifi 2022.12.7 to easy-install.pth file\n",
      "\n",
      "Installed /home/user/miniconda/lib/python3.7/site-packages/certifi-2022.12.7-py3.7.egg\n",
      "Searching for wheel\n",
      "Reading https://pypi.org/simple/wheel/\n",
      "Downloading https://files.pythonhosted.org/packages/bd/7c/d38a0b30ce22fc26ed7dbc087c6d00851fb3395e9d0dac40bec1f905030c/wheel-0.38.4-py3-none-any.whl#sha256=b60533f3f5d530e971d6737ca6d58681ee434818fab630c83a734bb10c083ce8\n",
      "Best match: wheel 0.38.4\n",
      "Processing wheel-0.38.4-py3-none-any.whl\n",
      "Installing wheel-0.38.4-py3-none-any.whl to /home/user/miniconda/lib/python3.7/site-packages\n",
      "Adding wheel 0.38.4 to easy-install.pth file\n",
      "Installing wheel script to /home/user/miniconda/bin\n",
      "\n",
      "Installed /home/user/miniconda/lib/python3.7/site-packages/wheel-0.38.4-py3.7.egg\n",
      "Searching for requests==2.25.1\n",
      "Best match: requests 2.25.1\n",
      "Adding requests 2.25.1 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for filelock==3.9.0\n",
      "Best match: filelock 3.9.0\n",
      "Adding filelock 3.9.0 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for boto3==1.26.87\n",
      "Best match: boto3 1.26.87\n",
      "Adding boto3 1.26.87 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for numpy==1.21.6\n",
      "Best match: numpy 1.21.6\n",
      "Adding numpy 1.21.6 to easy-install.pth file\n",
      "Installing f2py script to /home/user/miniconda/bin\n",
      "Installing f2py3 script to /home/user/miniconda/bin\n",
      "Installing f2py3.7 script to /home/user/miniconda/bin\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for tqdm==4.61.2\n",
      "Best match: tqdm 4.61.2\n",
      "Adding tqdm 4.61.2 to easy-install.pth file\n",
      "Installing tqdm script to /home/user/miniconda/bin\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for torch==1.13.1\n",
      "Best match: torch 1.13.1\n",
      "Adding torch 1.13.1 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /home/user/miniconda/bin\n",
      "Installing convert-onnx-to-caffe2 script to /home/user/miniconda/bin\n",
      "Installing torchrun script to /home/user/miniconda/bin\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for tokenizers==0.13.2\n",
      "Best match: tokenizers 0.13.2\n",
      "Adding tokenizers 0.13.2 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for urllib3==1.26.6\n",
      "Best match: urllib3 1.26.6\n",
      "Adding urllib3 1.26.6 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for chardet==4.0.0\n",
      "Best match: chardet 4.0.0\n",
      "Adding chardet 4.0.0 to easy-install.pth file\n",
      "Installing chardetect script to /home/user/miniconda/bin\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for idna==2.10\n",
      "Best match: idna 2.10\n",
      "Adding idna 2.10 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for jmespath==1.0.1\n",
      "Best match: jmespath 1.0.1\n",
      "Adding jmespath 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for s3transfer==0.6.0\n",
      "Best match: s3transfer 0.6.0\n",
      "Adding s3transfer 0.6.0 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for botocore==1.29.87\n",
      "Best match: botocore 1.29.87\n",
      "Adding botocore 1.29.87 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for nvidia-cublas-cu11==11.10.3.66\n",
      "Best match: nvidia-cublas-cu11 11.10.3.66\n",
      "Adding nvidia-cublas-cu11 11.10.3.66 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for nvidia-cuda-runtime-cu11==11.7.99\n",
      "Best match: nvidia-cuda-runtime-cu11 11.7.99\n",
      "Adding nvidia-cuda-runtime-cu11 11.7.99 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for nvidia-cudnn-cu11==8.5.0.96\n",
      "Best match: nvidia-cudnn-cu11 8.5.0.96\n",
      "Adding nvidia-cudnn-cu11 8.5.0.96 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "Best match: nvidia-cuda-nvrtc-cu11 11.7.99\n",
      "Adding nvidia-cuda-nvrtc-cu11 11.7.99 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for typing-extensions==4.4.0\n",
      "Best match: typing-extensions 4.4.0\n",
      "Adding typing-extensions 4.4.0 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for setuptools==52.0.0.post20210125\n",
      "Best match: setuptools 52.0.0.post20210125\n",
      "Adding setuptools 52.0.0.post20210125 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /home/user/miniconda/lib/python3.7/site-packages\n",
      "Finished processing dependencies for awesome-align==0.1.7\n"
     ]
    }
   ],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b0a870-1485-4807-8e60-84e903728465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:55:44.999794Z",
     "iopub.status.busy": "2023-02-12T00:55:44.999242Z",
     "iopub.status.idle": "2023-02-12T00:56:05.914777Z",
     "shell.execute_reply": "2023-02-12T00:56:05.913870Z",
     "shell.execute_reply.started": "2023-02-12T00:55:44.999745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/12/2023 00:55:48 - WARNING - awesome_align.run_train -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json not found in cache or force_download set to True, downloading to /home/user/.cache/torch/awesome-align/tmpytqmdd7v\n",
      "Downloading: 100%|██████████████████████████████| 625/625 [00:00<00:00, 502kB/s]\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json in cache at /home/user/.cache/torch/awesome-align/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.file_utils -   creating metadata file for /home/user/.cache/torch/awesome-align/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/user/.cache/torch/awesome-align/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt not found in cache or force_download set to True, downloading to /home/user/.cache/torch/awesome-align/tmptowfjssq\n",
      "Downloading: 100%|███████████████████████████| 996k/996k [00:00<00:00, 16.2MB/s]\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt in cache at /home/user/.cache/torch/awesome-align/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.file_utils -   creating metadata file for /home/user/.cache/torch/awesome-align/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/user/.cache/torch/awesome-align/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "02/12/2023 00:55:48 - INFO - awesome_align.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /home/user/.cache/torch/awesome-align/tmpiz8o6ii1\n",
      "Downloading:  35%|█████████▍                 | 249M/714M [00:07<00:50, 9.25MB/s]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniconda//bin/awesome-train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('awesome-align==0.1.7', 'console_scripts', 'awesome-train')())\n",
      "  File \"/home/user/miniconda/lib/python3.7/site-packages/awesome_align-0.1.7-py3.7.egg/awesome_align/run_train.py\", line 826, in main\n",
      "  File \"/home/user/miniconda/lib/python3.7/site-packages/awesome_align-0.1.7-py3.7.egg/awesome_align/modeling_utils.py\", line 437, in from_pretrained\n",
      "  File \"/home/user/miniconda/lib/python3.7/site-packages/awesome_align-0.1.7-py3.7.egg/awesome_align/file_utils.py\", line 254, in cached_path\n",
      "  File \"/home/user/miniconda/lib/python3.7/site-packages/awesome_align-0.1.7-py3.7.egg/awesome_align/file_utils.py\", line 487, in get_from_cache\n",
      "  File \"/home/user/miniconda/lib/python3.7/site-packages/awesome_align-0.1.7-py3.7.egg/awesome_align/file_utils.py\", line 375, in http_get\n",
      "  File \"/home/user/miniconda/lib/python3.7/site-packages/requests/models.py\", line 753, in generate\n",
      "    for chunk in self.raw.stream(chunk_size, decode_content=True):\n",
      "  File \"/home/user/miniconda/lib/python3.7/site-packages/urllib3/response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/user/miniconda/lib/python3.7/site-packages/urllib3/response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/user/miniconda/lib/python3.7/http/client.py\", line 447, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/home/user/miniconda/lib/python3.7/http/client.py\", line 491, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/home/user/miniconda/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/user/miniconda/lib/python3.7/ssl.py\", line 1052, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/user/miniconda/lib/python3.7/ssl.py\", line 911, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n",
      "Downloading:  35%|█████████▍                 | 251M/714M [00:08<00:15, 30.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "#!TRAIN_FILE=/examples/enfr.src-tgt\n",
    "#!EVAL_FILE=/examples/enfr.gold\n",
    "#!OUTPUT_DIR=/out\n",
    "\n",
    "#!CUDA_VISIBLE_DEVICES=0 awesome-train \\\n",
    "#    --output_dir=out \\\n",
    "#    --model_name_or_path=bert-base-multilingual-cased \\\n",
    "#    --extraction 'softmax' \\\n",
    "#    --do_train \\\n",
    "#    --train_tlm \\\n",
    "#    --train_so \\\n",
    "#    --train_data_file=examples/enfr.gold \\\n",
    "#    --per_gpu_train_batch_size 2 \\\n",
    "#    --gradient_accumulation_steps 4 \\\n",
    "#    --num_train_epochs 1 \\\n",
    "#    --learning_rate 2e-5 \\\n",
    "#    --save_steps 4000 \\\n",
    "#    --max_steps 20000 \\\n",
    "#    --do_eval \\\n",
    "#    --eval_data_file=examples/enfr.gold \\\n",
    "#    --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af2564cc-1af4-4b32-bc4d-d67197402781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T15:38:10.632084Z",
     "iopub.status.busy": "2023-01-28T15:38:10.631757Z",
     "iopub.status.idle": "2023-01-28T15:41:19.636427Z",
     "shell.execute_reply": "2023-01-28T15:41:19.635208Z",
     "shell.execute_reply.started": "2023-01-28T15:38:10.632051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/28/2023 15:38:12 - WARNING - awesome_align.run_train -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "01/28/2023 15:38:12 - INFO - awesome_align.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/user/.cache/torch/awesome-align/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0\n",
      "01/28/2023 15:38:12 - INFO - awesome_align.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "01/28/2023 15:38:12 - INFO - awesome_align.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/user/.cache/torch/awesome-align/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "01/28/2023 15:38:12 - INFO - awesome_align.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/user/.cache/torch/awesome-align/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "01/28/2023 15:38:19 - INFO - awesome_align.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias', 'psi_cls.bias', 'psi_cls.transform.weight', 'psi_cls.transform.bias', 'psi_cls.decoder.weight', 'psi_cls.decoder.bias']\n",
      "01/28/2023 15:38:19 - INFO - awesome_align.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "01/28/2023 15:38:21 - INFO - awesome_align.run_train -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, align_layer=8, block_size=512, cache_data=False, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_data_file='examples/enfr.src-tgt', eval_gold_file=None, extraction='softmax', fp16=False, fp16_opt_level='O1', gold_one_index=False, gradient_accumulation_steps=4, ignore_possible_alignments=False, learning_rate=2e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=40000, mlm_probability=0.15, model_name_or_path='bert-base-multilingual-cased', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='out', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=2, per_gpu_train_batch_size=2, save_steps=10000, save_total_limit=None, seed=42, should_continue=False, softmax_threshold=0.001, tokenizer_name=None, train_co=False, train_data_file='examples/enfr.src-tgt', train_gold_file=None, train_mlm=True, train_psi=True, train_so=True, train_tlm=True, train_tlm_full=True, warmup_steps=0, weight_decay=0.0)\n",
      "01/28/2023 15:38:21 - INFO - awesome_align.run_train -   Creating features from dataset file at examples/enfr.src-tgt\n",
      "Loading data: 100%|██████████████████████████| 447/447 [00:00<00:00, 714.58it/s]\n",
      "01/28/2023 15:38:21 - INFO - awesome_align.run_train -   ***** Running training *****\n",
      "01/28/2023 15:38:21 - INFO - awesome_align.run_train -     Num examples = 447\n",
      "01/28/2023 15:38:21 - INFO - awesome_align.run_train -     Num Epochs = 1\n",
      "01/28/2023 15:38:21 - INFO - awesome_align.run_train -     Instantaneous batch size per GPU = 2\n",
      "01/28/2023 15:38:21 - INFO - awesome_align.run_train -     Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "01/28/2023 15:38:21 - INFO - awesome_align.run_train -     Gradient Accumulation steps = 4\n",
      "01/28/2023 15:38:21 - INFO - awesome_align.run_train -     Total optimization steps = 56\n",
      "Iteration: 100%|████████████████████████████████| 56/56 [01:50<00:00,  1.95s/it]01/28/2023 15:40:12 - INFO - awesome_align.run_train -    global_step = 56, average loss = 10.733777810506362\n",
      "01/28/2023 15:40:12 - INFO - awesome_align.run_train -   Saving trained model checkpoint to out\n",
      "01/28/2023 15:40:12 - INFO - awesome_align.configuration_utils -   Configuration saved in out/config.json\n",
      "01/28/2023 15:40:19 - INFO - awesome_align.modeling_utils -   Model weights saved in out/pytorch_model.bin\n",
      "Iteration: 100%|████████████████████████████████| 56/56 [01:57<00:00,  2.10s/it]\n",
      "01/28/2023 15:40:20 - INFO - awesome_align.configuration_utils -   loading configuration file out/config.json\n",
      "01/28/2023 15:40:20 - INFO - awesome_align.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "01/28/2023 15:40:20 - INFO - awesome_align.modeling_utils -   loading weights file out/pytorch_model.bin\n",
      "01/28/2023 15:40:26 - INFO - awesome_align.tokenization_utils -   Model name 'out' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'out' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "01/28/2023 15:40:26 - INFO - awesome_align.tokenization_utils -   Didn't find file out/added_tokens.json. We won't load it.\n",
      "01/28/2023 15:40:26 - INFO - awesome_align.tokenization_utils -   loading file out/vocab.txt\n",
      "01/28/2023 15:40:26 - INFO - awesome_align.tokenization_utils -   loading file None\n",
      "01/28/2023 15:40:26 - INFO - awesome_align.tokenization_utils -   loading file out/special_tokens_map.json\n",
      "01/28/2023 15:40:26 - INFO - awesome_align.tokenization_utils -   loading file out/tokenizer_config.json\n",
      "01/28/2023 15:40:27 - INFO - awesome_align.run_train -   Evaluate the following checkpoints: ['out']\n",
      "01/28/2023 15:40:27 - INFO - awesome_align.configuration_utils -   loading configuration file out/config.json\n",
      "01/28/2023 15:40:27 - INFO - awesome_align.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "01/28/2023 15:40:27 - INFO - awesome_align.modeling_utils -   loading weights file out/pytorch_model.bin\n",
      "01/28/2023 15:40:34 - INFO - awesome_align.run_train -   Creating features from dataset file at examples/enfr.src-tgt\n",
      "Loading data: 100%|██████████████████████████| 447/447 [00:00<00:00, 728.27it/s]\n",
      "01/28/2023 15:40:34 - INFO - awesome_align.run_train -   ***** Running evaluation  *****\n",
      "01/28/2023 15:40:34 - INFO - awesome_align.run_train -     Num examples = 447\n",
      "01/28/2023 15:40:34 - INFO - awesome_align.run_train -     Batch size = 2\n",
      "Evaluating: 100%|█████████████████████████████| 224/224 [00:43<00:00,  5.10it/s]\n",
      "01/28/2023 15:41:18 - INFO - awesome_align.run_train -   ***** Eval results  *****\n",
      "01/28/2023 15:41:18 - INFO - awesome_align.run_train -     perplexity = tensor(2673.0999)\n",
      "{'perplexity_': tensor(2673.0999)}\n"
     ]
    }
   ],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 awesome-train \\\n",
    "#    --output_dir=out \\\n",
    "#    --model_name_or_path=bert-base-multilingual-cased \\\n",
    "#    --extraction 'softmax' \\\n",
    "#    --do_train \\\n",
    "#    --train_mlm \\\n",
    "#    --train_tlm \\\n",
    "#    --train_tlm_full \\\n",
    "#    --train_so \\\n",
    "#    --train_psi \\\n",
    "#    --train_data_file=examples/enfr.src-tgt \\\n",
    "#    --per_gpu_train_batch_size 2 \\\n",
    "#    --gradient_accumulation_steps 4 \\\n",
    "#    --num_train_epochs 1 \\\n",
    "#    --learning_rate 2e-5 \\\n",
    "#    --save_steps 10000 \\\n",
    "#    --max_steps 40000 \\\n",
    "#    --do_eval \\\n",
    "#    --eval_data_file=examples/enfr.src-tgt \\\n",
    "#    --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e6a364-2d93-43f4-b858-ccaafde79490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T16:20:08.806788Z",
     "iopub.status.busy": "2023-03-09T16:20:08.806422Z",
     "iopub.status.idle": "2023-03-09T16:20:24.478952Z",
     "shell.execute_reply": "2023-03-09T16:20:24.478163Z",
     "shell.execute_reply.started": "2023-03-09T16:20:08.806760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Extracting: 100it [00:01, 69.04it/s]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 awesome-align \\\n",
    "    --output_file=out/output.txt \\\n",
    "    --model_name_or_path=out/checkpoint-5080 \\\n",
    "    --data_file=examples/integrate.txt \\\n",
    "    --extraction 'softmax' \\\n",
    "    --batch_size 32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
